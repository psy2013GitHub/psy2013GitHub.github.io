{"meta":{"title":"Flappy","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com"},"pages":[{"title":"","date":"2016-12-16T22:29:29.668Z","updated":"2016-12-16T22:13:57.562Z","comments":true,"path":"esl_notes/esl_notes-aic_bic.html","permalink":"http://yoursite.com/esl_notes/esl_notes-aic_bic.html","excerpt":"","text":"aic/bic code{white-space: pre;} pre:not([class]) { background-color: white; } if (window.hljs && document.readyState && document.readyState === \"complete\") { window.setTimeout(function() { hljs.initHighlighting(); }, 0); } h1 { font-size: 34px; } h1.title { font-size: 38px; } h2 { font-size: 30px; } h3 { font-size: 24px; } h4 { font-size: 18px; } h5 { font-size: 16px; } h6 { font-size: 12px; } .table th:not([align]) { text-align: left; } .main-container { max-width: 940px; margin-left: auto; margin-right: auto; } code { color: inherit; background-color: rgba(0, 0, 0, 0.04); } img { max-width:100%; height: auto; } .tabbed-pane { padding-top: 12px; } button.code-folding-btn:focus { outline: none; } $(document).ready(function () { window.buildTabsets(\"TOC\"); }); aic/bic deng.zhou 2016/12/14 使用training数据固定\\(X\\)，对\\(Y\\)求期望来估计泛化误差 假设train data是 \\(X\\), \\(Y_0\\)，那么有 \\(\\overline{err} = \\sum{L(\\hat{y_i}, y_{0i})}\\) 如果新得(未出现得)数据是 \\(X\\), \\(Y_1\\)，那么有 \\(Err = \\sum{L(\\hat{y_i}, y_{1i})}\\) \\(Err\\) 和 \\(\\overline{err}\\)得关系是 \\[\\begin{eqnarray*} Err - \\overline{err} \\equiv op \\end{eqnarray*}\\] 对上式求对Y得期望 \\(E_y(Err) - E_y(\\overline{err}) = E_y(op)\\) 有人证明。。。。 \\[\\begin{eqnarray*} E_y(op) &amp;=&amp; \\frac{2}{N} \\cdot \\sum{Cov(\\hat{y_i}, y_i)} \\end{eqnarray*}\\] 特别得，当linear model时 \\[\\begin{eqnarray*} \\beta &amp;=&amp; (X^TX)^{-1}X^TY \\\\ H &amp;=&amp; X(X^TX)^{-1}X^TY \\\\ \\hat{H} &amp;=&amp; HY \\end{eqnarray*}\\] \\[\\begin{eqnarray*} E_y(op) &amp;=&amp; \\frac{2}{N} \\cdot \\sum{Cov(\\hat{y_i}, y_i)} \\\\ &amp;=&amp; \\frac{2}{N} \\cdot \\sum{Cov(x_i^T\\beta[i], y_i)} \\\\ &amp;=&amp; \\frac{2}{N} \\cdot \\sum{Cov(x_i^T(X^TX)^{-1}X^Ty_i, y_i)} \\\\ &amp;=&amp; \\frac{2}{N} \\cdot tr(HCov(Y,Y)) \\\\ &amp;=&amp; \\frac{2}{N} \\cdot \\sigma_{\\varepsilon}^{2} \\cdot tr(H) \\\\ &amp;=&amp; \\frac{2}{N} \\cdot \\sigma_{\\varepsilon}^{2} \\cdot tr(X(X^TX)^{-1}X^T) \\\\ &amp;=&amp; \\frac{2}{N} \\cdot \\sigma_{\\varepsilon}^{2} \\cdot tr(X^TX(X^TX)^{-1}) \\\\ &amp;=&amp; \\frac{2}{N} \\cdot \\sigma_{\\varepsilon}^{2} \\cdot tr(I_d) \\\\ &amp;=&amp; \\frac{2}{N} \\cdot d\\sigma_{\\varepsilon}^{2} \\\\ \\end{eqnarray*}\\] Efron,1986 证明过，上式对于linear model + square-loss成立； 对于linear model + log-loss近似成立； 对于0-1 loss不成立，然而有得人仍然这样用—。— 当err是用负对数似然表示时, 同时 \\(N \\to \\infty\\)时 \\[\\begin{eqnarray*} E_y(Err) &amp; = &amp; E_y(\\log{like}) \\\\ &amp; = &amp; \\hat{err} + \\frac{2}{N} \\cdot \\sum{Cov(\\hat{y_i}, y_i)} \\\\ &amp; = &amp; \\log{like} + \\frac{2}{N} \\cdot \\sum{Cov(\\hat{y_i}, y_i)} \\\\ \\text{若满足上面特定条件} &amp; = &amp; \\log{like} + \\frac{2}{N} \\cdot d\\sigma_{\\varepsilon}^{2} \\\\ \\text{当 $N \\to \\infty$时} &amp; \\approx &amp; \\log{like} + 2\\frac{d}{N} \\\\ \\text{以上，我们推导出了AIC} \\end{eqnarray*}\\] AIC 定义： \\[\\begin{eqnarray*} －\\frac{2}{N} \\cdot loglik + 2\\frac{d}{N} \\end{eqnarray*}\\] 总结 AIC是对\\(E_y(Err)\\)在linear model + log-loss下得近似 BIC 定义： \\[\\begin{eqnarray*} -2 \\cdot loglik + \\log{N} \\cdot d \\end{eqnarray*}\\] 由来： \\[ obj : \\max P(M_k|D) \\] \\[\\begin{eqnarray*} P(M_k|D) &amp;\\varpropto&amp; P(M_k, D) \\\\ &amp;=&amp; P(M_k) \\cdot P(D|M_k) \\\\ &amp;=&amp; P(M_k) \\cdot \\int P(D|\\theta, M_k)P(\\theta|M_k) d_{\\theta} \\end{eqnarray*}\\] 上式后面得积分难以计算，使用laplace近似 \\[\\begin{eqnarray*} \\log{P(D|M_k)} = \\log{P(D|\\hat{\\theta},M_k)} - \\frac{d_m}{2} \\cdot \\log{N} + O(1) \\end{eqnarray*}\\] 总结 BIC就是假设对模型后面概率得比较（前提是假设模型得先验概率相等） ### 与AIC得关系 对模型复杂度惩罚更高 // add bootstrap table styles to pandoc tables function bootstrapStylePandocTables() { $('tr.header').parent('thead').parent('table').addClass('table table-condensed'); } $(document).ready(function () { bootstrapStylePandocTables(); }); (function () { var script = document.createElement(\"script\"); script.type = \"text/javascript\"; script.src = \"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"; document.getElementsByTagName(\"head\")[0].appendChild(script); })();"}],"posts":[{"title":"els-chapt7-model-eval","slug":"els-chapt7-model-eval","date":"2016-12-16T23:32:21.000Z","updated":"2017-01-16T00:38:08.425Z","comments":true,"path":"2016/12/17/els-chapt7-model-eval/","link":"","permalink":"http://yoursite.com/2016/12/17/els-chapt7-model-eval/","excerpt":"","text":"从今天开始做esl得笔记，hexo上传html比较麻烦，直接发在rpubs.org好了，妈个鸡，上传真得很慢。。。用chrome打开链接 chap7 AIC/BIC VC dimension Cross Validation chapt8 MLE EM Model Avg bayes内容看prml吧，后面有时间再更。。。","categories":[{"name":"notes","slug":"notes","permalink":"http://yoursite.com/categories/notes/"}],"tags":[{"name":"esl","slug":"esl","permalink":"http://yoursite.com/tags/esl/"}]},{"title":"leetcode - string","slug":"leetcode-string","date":"2016-12-04T08:10:46.000Z","updated":"2016-12-04T12:42:40.629Z","comments":true,"path":"2016/12/04/leetcode-string/","link":"","permalink":"http://yoursite.com/2016/12/04/leetcode-string/","excerpt":"","text":"edit distance: DP generate paranthes: Iterative Recursive integer to english words: Unit(every 3) Recurvise interleaving string: Iterative Recusive/DP longest valid parenthes: Stack存分界符 (注意’)’pop分情况) minimum window substring: 双指针法。1，找到满足子串；2，移动start使之成为最短 palindrom pairs: 分3种情况回文, O(n)空间换时间从O($n^2$)为O(n) shortest palindrom: 找到最长回文子串即可 regular expression matching: DP wilcard matching: DP valid number: regexp/NFS scramble string: Substring Recursive word ladder II: 构建非重复前向路径","categories":[{"name":"dsa","slug":"dsa","permalink":"http://yoursite.com/categories/dsa/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Hello World","slug":"hello-world","date":"2016-12-03T07:12:58.203Z","updated":"2016-12-03T07:12:58.213Z","comments":true,"path":"2016/12/03/hello-world/","link":"","permalink":"http://yoursite.com/2016/12/03/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}